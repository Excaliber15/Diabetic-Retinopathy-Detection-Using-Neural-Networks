ğŸ©º Diabetic Retinopathy Detection â€“ APTOS 2019
Imagine being able to detect blindness before it happens.

Diabetic Retinopathy (DR) is the leading cause of blindness in working-aged adults worldwide. In India, Aravind Eye Hospital aims to prevent this irreversible disease among people in rural regions by automating early detection. This project supports that mission using machine learning to identify the severity of DR from retinal fundus images.

Using thousands of images collected in underserved areas, this solution leverages both custom CNN models and transfer learning (ResNetV2-50) to accurately classify the stage of DR â€” from no disease to severe proliferative stages.

ğŸŒ Real-World Motivation
Currently, Aravind Eye Hospital sends technicians to rural areas to capture retinal images. These are then manually reviewed by trained ophthalmologists â€” a slow, costly, and capacity-limited process.

By automating image screening through deep learning, this system will:

Speed up diagnosis

Help scale rural outreach programs

Prevent lifelong blindness

Provide a scalable model for other diseases (e.g., glaucoma, macular degeneration)

This project aligns with the goals of the 4th Asia Pacific Tele-Ophthalmology Society (APTOS) Symposium, helping to develop deployable, accurate AI systems in real-world ophthalmology.

ğŸ—‚ï¸ Dataset Description
ğŸ“¦ Source: APTOS 2019 Blindness Detection

ğŸ–¼ï¸ Data: Fundus images under varied conditions and equipment

ğŸ§  Labels: DR severity (0â€“4) assigned by certified clinicians:

0: No DR

1: Mild

2: Moderate

3: Severe

4: Proliferative DR

ğŸ“Œ Real-World Challenges:
The data includes artifacts, blurring, over/underexposure, and camera variation. Models must generalize despite these variations.

ğŸ” Problem Statement
Your model should predict the probability (0.0â€“1.0) that an image contains malignant lesions. Though the training labels are multiclass (0â€“4), the evaluation task simplifies the classification into a binary probability of DR presence.

ğŸš€ Solution Overview
ğŸ”¹ Data Preprocessing
Downloaded with kagglehub

Image resizing, normalization

Augmentation (zoom, flip, brightness) using ImageDataGenerator

Train/test split with stratification

ğŸ”¹ Models Used
ğŸ§± Custom CNN
Convolutional layers with pooling, dropout, and batch normalization

Trained with Cosine Annealing for dynamic learning rate adaptation

Test Accuracy: ~75%

ğŸ—ï¸ ResNetV2-50 (Transfer Learning)
Pre-trained on ImageNet

Top layers replaced with custom dense layers

Fine-tuned on fundus images

Test Accuracy: ~80%

ğŸ” Learning Rate Strategy
âœ… Cosine Annealing is used for the CNN to gradually reduce the learning rate and avoid local minima.

Implemented via tf.keras.callbacks.LearningRateScheduler.

ğŸ“Š Model Performance Summary
Model	Epochs	Learning Rate Strategy	Test Accuracy
Custom CNN	10	Cosine Annealing	~75%
ResNetV2-50 (TL)	10	Reduced LR	~80%

ğŸ§° Tech Stack
Python

TensorFlow / Keras

OpenCV

Scikit-learn

Seaborn, Matplotlib

kagglehub for dataset access

ğŸ—ƒï¸ Files Structure
train.csv â€“ Training labels

test.csv â€“ Test image IDs

train.zip â€“ Training images

test.zip â€“ Test images

Notebook â€“ Full preprocessing, modeling, and evaluation code

